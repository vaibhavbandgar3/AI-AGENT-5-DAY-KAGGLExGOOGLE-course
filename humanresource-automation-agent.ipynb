{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"54a3d943","cell_type":"markdown","source":"# HR Lifecycle Automation Agent\n**Objective:** Implement a full HR lifecycle automation system (recruit â†’ screen â†’ schedule â†’ onboard â†’ performance â†’ offboard) tools a single global LlmAgent (Gemini), function-based prompts, tools, A2A exposure, memory, retry, sequential/parallel/loop agents, and evaluation metrics.","metadata":{}},{"id":"312bcf00","cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"âœ… Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:15.266141Z","iopub.execute_input":"2025-12-01T19:20:15.266502Z","iopub.status.idle":"2025-12-01T19:20:15.347721Z","shell.execute_reply.started":"2025-12-01T19:20:15.266475Z","shell.execute_reply":"2025-12-01T19:20:15.346635Z"}},"outputs":[{"name":"stdout","text":"âœ… Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":1},{"id":"9b540ca8","cell_type":"markdown","source":"## Imports\nBring in Google ADK / GenAI, standard utilities, concurrency and data tools.","metadata":{}},{"id":"ec61e540","cell_type":"code","source":"# Google ADK / GenAI (as in main.ipynb)\nfrom google.adk.agents import LlmAgent\nfrom google.adk.a2a.utils.agent_to_a2a import to_a2a\nfrom google.adk.models.google_llm import Gemini\nfrom google.genai import types\n\n# Standard utilities\nimport os\nimport json\nimport re\nfrom pathlib import Path\nfrom collections import defaultdict\nimport datetime\nimport time\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport subprocess\n\n# Data & plotting\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:15.349223Z","iopub.execute_input":"2025-12-01T19:20:15.349491Z","iopub.status.idle":"2025-12-01T19:20:54.469375Z","shell.execute_reply.started":"2025-12-01T19:20:15.349464Z","shell.execute_reply":"2025-12-01T19:20:54.468605Z"}},"outputs":[],"execution_count":2},{"id":"80169bc9","cell_type":"markdown","source":"## Top-level configuration\nEditable constants: model name, retry settings, data/memory paths, concurrency.","metadata":{}},{"id":"ae5acea9","cell_type":"code","source":"MODEL_NAME = \"gemini-2.5-pro\"\n\nRETRY_CONFIG = types.HttpRetryOptions(\n    attempts=3,\n    exp_base=2,\n    initial_delay=1,\n    http_status_codes=[429, 500, 502, 503, 504],\n)\n\nDATA_DIR = Path(\"data\")\nDATA_DIR.mkdir(parents=True, exist_ok=True)\nMEMORY_FILE = DATA_DIR / \"memory_store.json\"\nMETRICS_DIR = DATA_DIR / \"metrics\"\nMETRICS_DIR.mkdir(parents=True, exist_ok=True)\n\nA2A_HOST = \"127.0.0.1\"\nA2A_PORT = 8000\n\nMAX_WORKERS = 4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.470183Z","iopub.execute_input":"2025-12-01T19:20:54.470624Z","iopub.status.idle":"2025-12-01T19:20:54.476886Z","shell.execute_reply.started":"2025-12-01T19:20:54.470604Z","shell.execute_reply":"2025-12-01T19:20:54.476080Z"}},"outputs":[],"execution_count":3},{"id":"f35f663c","cell_type":"markdown","source":"## Helpers\nLogging, context compaction, JSON read/write helpers (kept small and deterministic).","metadata":{}},{"id":"246f47fc","cell_type":"code","source":"def log(msg):\n    ts = datetime.datetime.now().isoformat()\n    print(f\"[{ts}] {msg}\")\n\ndef compact_context(messages, max_tokens=1500):\n    # simple greedy compaction (message lengths by characters)\n    joined = []\n    total = 0\n    for m in reversed(messages):\n        l = len(m)\n        if total + l > max_tokens:\n            break\n        joined.append(m)\n        total += l\n    return \"\\n\\n\".join(reversed(joined))\n\ndef safe_write_json(path: Path, obj):\n    path.parent.mkdir(parents=True, exist_ok=True)\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(obj, f, indent=2, ensure_ascii=False)\n\ndef safe_read_json(path: Path):\n    if not path.exists():\n        return {}\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.477839Z","iopub.execute_input":"2025-12-01T19:20:54.478129Z","iopub.status.idle":"2025-12-01T19:20:54.499933Z","shell.execute_reply.started":"2025-12-01T19:20:54.478102Z","shell.execute_reply":"2025-12-01T19:20:54.498831Z"}},"outputs":[],"execution_count":4},{"id":"6d5387c6","cell_type":"markdown","source":"## Demo datasets and templates\nCreate small synthetic candidate dataset and example job description/templates for onboarding/offboarding/performance.","metadata":{}},{"id":"c5bd41f1","cell_type":"code","source":"people = [\n    {\"id\": 1, \"name\": \"Priya Sharma\", \"email\": \"priya+demo@example.com\",\n     \"experience_years\": 4, \"skills\": \"python, machine learning, pandas, sql\",\n     \"resume_text\": \"Priya worked on ML models, ETL pipelines and productionized models using Python and pandas. 4 years experience.\"},\n    {\"id\": 2, \"name\": \"Rahul Verma\", \"email\": \"rahul+demo@example.com\",\n     \"experience_years\": 6, \"skills\": \"java, spring, microservices, sql\",\n     \"resume_text\": \"Rahul is an experienced backend engineer focused on microservices and distributed systems. 6 years experience.\"},\n    {\"id\": 3, \"name\": \"Ananya Desai\", \"email\": \"ananya+demo@example.com\",\n     \"experience_years\": 2, \"skills\": \"react, javascript, ui, css\",\n     \"resume_text\": \"Ananya has built modern UI with React and strong product sensibilities. 2 years experience.\"},\n]\n\ndf_people = pd.DataFrame(people)\ncsv_path = DATA_DIR / \"people_demo.csv\"\ndf_people.to_csv(csv_path, index=False)\nlog(f\"Saved demo people dataset to {csv_path}\")\n\nJOB_JD = {\n    \"id\": \"jd_001\",\n    \"title\": \"Machine Learning Engineer\",\n    \"min_experience\": 3,\n    \"must_have\": [\"python\", \"machine learning\", \"pandas\"],\n    \"nice_to_have\": [\"sql\", \"docker\"]\n}\n\nONBOARDING_TEMPLATE = \"Welcome {name} to {role}. Day {day}: {tasks}\"\nOFFBOARDING_TEMPLATE = \"Offboard {name}: {tasks}\"\nPERFORMANCE_TEMPLATE = \"Performance summary for {name}: {summary}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.502666Z","iopub.execute_input":"2025-12-01T19:20:54.502970Z","iopub.status.idle":"2025-12-01T19:20:54.527449Z","shell.execute_reply.started":"2025-12-01T19:20:54.502948Z","shell.execute_reply":"2025-12-01T19:20:54.526532Z"}},"outputs":[{"name":"stdout","text":"[2025-12-01T19:20:54.524230] Saved demo people dataset to data/people_demo.csv\n","output_type":"stream"}],"execution_count":5},{"id":"35bad1c9","cell_type":"markdown","source":"## Resume parser\nDeterministic function to extract skills and approximate experience (used by screening/onboarding/offboarding).","metadata":{}},{"id":"75bdbf13","cell_type":"code","source":"def parse_resume_text(resume_text):\n    txt = (resume_text or \"\").lower()\n    known_skills = [\"python\",\"machine learning\",\"pandas\",\"sql\",\"java\",\"spring\",\"microservices\",\"react\",\"javascript\",\"docker\",\"etl\",\"ui\",\"css\"]\n    found = [s for s in known_skills if s in txt]\n    years_match = re.search(r\"(\\d+)\\s*(?:years|yrs)\", txt)\n    years = int(years_match.group(1)) if years_match else None\n    summary = re.sub(r\"\\s+\", \" \", txt).strip()\n    return {\"skills\": found, \"experience_years\": years, \"summary\": summary}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.528273Z","iopub.execute_input":"2025-12-01T19:20:54.528549Z","iopub.status.idle":"2025-12-01T19:20:54.538072Z","shell.execute_reply.started":"2025-12-01T19:20:54.528522Z","shell.execute_reply":"2025-12-01T19:20:54.537336Z"}},"outputs":[],"execution_count":6},{"id":"fca739ae","cell_type":"markdown","source":"## Tools\nImplement the code-execution tool (sandbox wrapper) and mock search tool (replace with real search if you want).\nThese are passed in to the global agent as tools (same pattern as your main.ipynb).","metadata":{}},{"id":"83f70931","cell_type":"code","source":"def code_execution_tool(code_str, timeout=5):\n    \"\"\"\n    Simple subprocess based runner. Not secure for untrusted code.\n    \"\"\"\n    try:\n        proc = subprocess.Popen([\"python3\", \"-c\", code_str],\n                                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n        stdout, stderr = proc.communicate(timeout=timeout)\n        return {\"stdout\": stdout, \"stderr\": stderr, \"returncode\": proc.returncode}\n    except subprocess.TimeoutExpired:\n        proc.kill()\n        return {\"stdout\": \"\", \"stderr\": \"Timeout\", \"returncode\": -1}\n    except Exception as e:\n        return {\"stdout\": \"\", \"stderr\": str(e), \"returncode\": -2}\n\ndef mock_search_tool(query, top_k=3):\n    results = []\n    for p in people:\n        score = sum(1 for w in query.lower().split() if w in p[\"resume_text\"].lower())\n        results.append({\"id\": p[\"id\"], \"name\": p[\"name\"], \"score\": score, \"snippet\": p[\"resume_text\"][:200]})\n    results = sorted(results, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n    return results\n\n# Wrap simple tool descriptors if your main.ipynb expects dict-like tools\ncode_tool = {\"name\": \"code_exec\", \"callable\": code_execution_tool}\nsearch_tool = {\"name\": \"search\", \"callable\": mock_search_tool}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.538913Z","iopub.execute_input":"2025-12-01T19:20:54.539223Z","iopub.status.idle":"2025-12-01T19:20:54.552214Z","shell.execute_reply.started":"2025-12-01T19:20:54.539197Z","shell.execute_reply":"2025-12-01T19:20:54.551362Z"}},"outputs":[],"execution_count":7},{"id":"485bdb63","cell_type":"markdown","source":"## Create single global HR agent (exact style from your main.ipynb)\nWe create one global LlmAgent (hr_agent) with Gemini model, retry options and tools passed in. All tasks will use this same agent instance and call `hr_agent.run(prompt)` â€” exactly like your notebook.","metadata":{}},{"id":"17d17b29","cell_type":"code","source":"model = Gemini(model_name=MODEL_NAME)\ntools_list = [search_tool, code_tool]\n\nhr_agent = LlmAgent(\n    model=model,\n    tools=tools_list,\n    retry_options=RETRY_CONFIG\n)\n\nlog(\"Global HR agent (hr_agent) created with Gemini and retry config.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:23:55.285781Z","iopub.execute_input":"2025-12-01T19:23:55.286187Z","iopub.status.idle":"2025-12-01T19:23:55.309283Z","shell.execute_reply.started":"2025-12-01T19:23:55.286157Z","shell.execute_reply":"2025-12-01T19:23:55.308064Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/3578224523.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtools_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msearch_tool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_tool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m hr_agent = LlmAgent(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtools_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             warnings.warn(\n","\u001b[0;31mValidationError\u001b[0m: 8 validation errors for LlmAgent\nname\n  Field required [type=missing, input_value={'model': Gemini(model='g...,\n  initial_delay=1.0\n)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\ntools.0.callable\n  Input should be callable [type=callable_type, input_value={'name': 'search', 'calla...tool at 0x7c06161cab60>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/callable_type\ntools.0.is-instance[BaseTool]\n  Input should be an instance of BaseTool [type=is_instance_of, input_value={'name': 'search', 'calla...tool at 0x7c06161cab60>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/is_instance_of\ntools.0.is-instance[BaseToolset]\n  Input should be an instance of BaseToolset [type=is_instance_of, input_value={'name': 'search', 'calla...tool at 0x7c06161cab60>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/is_instance_of\ntools.1.callable\n  Input should be callable [type=callable_type, input_value={'name': 'code_exec', 'ca...tool at 0x7c06161caac0>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/callable_type\ntools.1.is-instance[BaseTool]\n  Input should be an instance of BaseTool [type=is_instance_of, input_value={'name': 'code_exec', 'ca...tool at 0x7c06161caac0>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/is_instance_of\ntools.1.is-instance[BaseToolset]\n  Input should be an instance of BaseToolset [type=is_instance_of, input_value={'name': 'code_exec', 'ca...tool at 0x7c06161caac0>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/is_instance_of\nretry_options\n  Extra inputs are not permitted [type=extra_forbidden, input_value=HttpRetryOptions(\n  attem...],\n  initial_delay=1.0\n), input_type=HttpRetryOptions]\n    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden"],"ename":"ValidationError","evalue":"8 validation errors for LlmAgent\nname\n  Field required [type=missing, input_value={'model': Gemini(model='g...,\n  initial_delay=1.0\n)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\ntools.0.callable\n  Input should be callable [type=callable_type, input_value={'name': 'search', 'calla...tool at 0x7c06161cab60>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/callable_type\ntools.0.is-instance[BaseTool]\n  Input should be an instance of BaseTool [type=is_instance_of, input_value={'name': 'search', 'calla...tool at 0x7c06161cab60>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/is_instance_of\ntools.0.is-instance[BaseToolset]\n  Input should be an instance of BaseToolset [type=is_instance_of, input_value={'name': 'search', 'calla...tool at 0x7c06161cab60>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/is_instance_of\ntools.1.callable\n  Input should be callable [type=callable_type, input_value={'name': 'code_exec', 'ca...tool at 0x7c06161caac0>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/callable_type\ntools.1.is-instance[BaseTool]\n  Input should be an instance of BaseTool [type=is_instance_of, input_value={'name': 'code_exec', 'ca...tool at 0x7c06161caac0>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/is_instance_of\ntools.1.is-instance[BaseToolset]\n  Input should be an instance of BaseToolset [type=is_instance_of, input_value={'name': 'code_exec', 'ca...tool at 0x7c06161caac0>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/is_instance_of\nretry_options\n  Extra inputs are not permitted [type=extra_forbidden, input_value=HttpRetryOptions(\n  attem...],\n  initial_delay=1.0\n), input_type=HttpRetryOptions]\n    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden","output_type":"error"}],"execution_count":9},{"id":"a1502698","cell_type":"markdown","source":"## LLM call wrapper\nSmall wrapper to call the single global hr_agent and robustly parse JSON responses (this mirrors patterns in your main.ipynb).","metadata":{}},{"id":"9f223e30","cell_type":"code","source":"def call_agent_and_parse(prompt):\n    \"\"\"\n    Call the global hr_agent with prompt and return parsed JSON or {'raw': text} on fallback.\n    \"\"\"\n    resp = hr_agent.run(prompt)  # matches your notebook pattern\n    text = resp if isinstance(resp, str) else getattr(resp, \"text\", str(resp))\n    try:\n        return json.loads(text)\n    except Exception:\n        m = re.search(r\"(\\{.*\\})\", text, flags=re.DOTALL)\n        if m:\n            try:\n                return json.loads(m.group(1))\n            except Exception:\n                return {\"raw\": text}\n        return {\"raw\": text}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.668512Z","iopub.status.idle":"2025-12-01T19:20:54.668779Z","shell.execute_reply.started":"2025-12-01T19:20:54.668641Z","shell.execute_reply":"2025-12-01T19:20:54.668652Z"}},"outputs":[],"execution_count":null},{"id":"9c5aae4a","cell_type":"markdown","source":"## Screening (prompt + function)\nBuild screening prompt, call hr_agent, and return structured output.","metadata":{}},{"id":"261d44f1","cell_type":"code","source":"def build_screening_prompt(candidate, jd):\n    parsed = parse_resume_text(candidate.get(\"resume_text\", \"\"))\n    candidate_summary = (\n        f\"Name: {candidate.get('name')}. Experience: {candidate.get('experience_years') or parsed.get('experience_years')}. \"\n        f\"Skills: {', '.join(parsed.get('skills', []))}. Resume: {parsed.get('summary')}\"\n    )\n    prompt = f\"\"\"\nYou are an HR screening assistant.\nJob Title: {jd['title']}\nJD must-have skills: {', '.join(jd['must_have'])}\nJD nice-to-have: {', '.join(jd.get('nice_to_have', []))}\n\nCandidate summary: {candidate_summary}\n\nTask:\n1) Provide a numeric suitability score 0-100.\n2) List matched skills from the JD.\n3) Short justification (1-2 sentences).\n4) Label: 'Strong Fit', 'Potential Fit', or 'Not a Fit'.\n\nReturn JSON with keys: score (number), matched_skills (list), justification (string), label (string).\n\"\"\"\n    return prompt\n\ndef screen_candidate(candidate, jd=JOB_JD):\n    prompt = build_screening_prompt(candidate, jd)\n    return call_agent_and_parse(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.670134Z","iopub.status.idle":"2025-12-01T19:20:54.670452Z","shell.execute_reply.started":"2025-12-01T19:20:54.670321Z","shell.execute_reply":"2025-12-01T19:20:54.670334Z"}},"outputs":[],"execution_count":null},{"id":"9f5b1aa1","cell_type":"markdown","source":"## Batch sequential runner\nRun screening sequentially across a DataFrame of candidates (mirror notebook's sequential agent pattern).","metadata":{}},{"id":"667c77d1","cell_type":"code","source":"def batch_screen_candidates(df_candidates, jd=JOB_JD):\n    results = []\n    for _, row in df_candidates.iterrows():\n        candidate = row.to_dict()\n        try:\n            out = screen_candidate(candidate, jd)\n            results.append({\"candidate_id\": candidate[\"id\"], \"name\": candidate[\"name\"], \"result\": out})\n            log(f\"Screened {candidate['name']} -> label: {out.get('label')}, score: {out.get('score')}\")\n        except Exception as e:\n            log(f\"Error screening {candidate['name']}: {e}\")\n            results.append({\"candidate_id\": candidate['id'], \"name\": candidate['name'], \"result\": {\"error\": str(e)}})\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.671388Z","iopub.status.idle":"2025-12-01T19:20:54.671730Z","shell.execute_reply.started":"2025-12-01T19:20:54.671554Z","shell.execute_reply":"2025-12-01T19:20:54.671569Z"}},"outputs":[],"execution_count":null},{"id":"953b2bfc","cell_type":"markdown","source":"## Parallel runner (ThreadPoolExecutor)\nRun screening in parallel using the same hr_agent (multiple concurrent calls).","metadata":{}},{"id":"ff0831d7","cell_type":"code","source":"def parallel_batch_screen_candidates(df_candidates, jd=JOB_JD, max_workers=MAX_WORKERS):\n    candidates = df_candidates.to_dict(orient=\"records\")\n    results = []\n\n    with ThreadPoolExecutor(max_workers=max_workers) as pool:\n        futures = {pool.submit(screen_candidate, c, jd): c for c in candidates}\n\n        for fut in as_completed(futures):\n            c = futures[fut]\n            try:\n                out = fut.result()\n                results.append({\n                    \"candidate_id\": c[\"id\"],\n                    \"name\": c[\"name\"],\n                    \"result\": out\n                })\n                log(f\"Parallel screened {c['name']} -> label: {out.get('label')}, score: {out.get('score')}\")\n            except Exception as e:\n                log(f\"Parallel screening error for {c['name']}: {e}\")\n                results.append({\n                    \"candidate_id\": c[\"id\"],\n                    \"name\": c[\"name\"],\n                    \"result\": {\"error\": str(e)}\n                })\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.673184Z","iopub.status.idle":"2025-12-01T19:20:54.673705Z","shell.execute_reply.started":"2025-12-01T19:20:54.673490Z","shell.execute_reply":"2025-12-01T19:20:54.673509Z"}},"outputs":[],"execution_count":null},{"id":"b2581115","cell_type":"markdown","source":"## Iterative refinement loop\nRun screening iteratively and refine shortlist until stable or max iterations reached.","metadata":{}},{"id":"82a3bc3b","cell_type":"code","source":"def iterative_refinement(initial_candidates, jd=JOB_JD, max_iters=5):\n    state = initial_candidates\n    for i in range(max_iters):\n        log(f\"Refinement iteration {i+1}\")\n        # run screening on current candidates\n        df_state = pd.DataFrame(state)\n        screened = batch_screen_candidates(df_state, jd)\n        # sort by score (if available) and keep top N\n        def score_of(r):\n            s = r.get(\"result\", {}).get(\"score\")\n            try:\n                return float(s) if s is not None else 0.0\n            except:\n                return 0.0\n        screened_sorted = sorted(screened, key=score_of, reverse=True)\n        top_ids = [r[\"candidate_id\"] for r in screened_sorted[:2]]\n        new_state = [next((p for p in state if p[\"id\"] == cid), None) for cid in top_ids]\n        new_state = [s for s in new_state if s]\n        # stop condition: if IDs unchanged\n        old_ids = [c[\"id\"] for c in state]\n        new_ids = [c[\"id\"] for c in new_state]\n        if old_ids == new_ids:\n            log(\"Refinement stable â€” stopping.\")\n            return screened_sorted\n        state = new_state\n    return screened_sorted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.674694Z","iopub.status.idle":"2025-12-01T19:20:54.675056Z","shell.execute_reply.started":"2025-12-01T19:20:54.674860Z","shell.execute_reply":"2025-12-01T19:20:54.674878Z"}},"outputs":[],"execution_count":null},{"id":"1b1bd42f","cell_type":"markdown","source":"## Onboarding (prompt + function)\nBuild onboarding prompt and call hr_agent (same agent).","metadata":{}},{"id":"8e607cf8","cell_type":"code","source":"def build_onboarding_prompt(candidate, role_title):\n    parsed = parse_resume_text(candidate.get(\"resume_text\", \"\"))\n    candidate_summary = f\"Name: {candidate.get('name')}. Skills: {', '.join(parsed.get('skills', []))}. Experience: {candidate.get('experience_years') or parsed.get('experience_years')}\"\n    prompt = f\"\"\"\nYou are an HR onboarding assistant for role: {role_title}.\nCandidate info: {candidate_summary}\n\nProduce:\n1) A 7-day onboarding checklist with daily tasks.\n2) Required accesses and documents.\n3) A short welcome message (1-2 sentences).\n\nReturn JSON: {{ \"checklist\": [{{\"day\":1,\"tasks\":[...]}}], \"accesses\": [...], \"welcome\": \"...\" }}\n\"\"\"\n    return prompt\n\ndef generate_onboarding(candidate, role_title):\n    prompt = build_onboarding_prompt(candidate, role_title)\n    return call_agent_and_parse(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.676176Z","iopub.status.idle":"2025-12-01T19:20:54.676542Z","shell.execute_reply.started":"2025-12-01T19:20:54.676366Z","shell.execute_reply":"2025-12-01T19:20:54.676381Z"}},"outputs":[],"execution_count":null},{"id":"175674e3","cell_type":"markdown","source":"## Offboarding (prompt + function)\nBuild offboarding prompt and call hr_agent.","metadata":{}},{"id":"361304a9","cell_type":"code","source":"def build_offboarding_prompt(candidate, role_title):\n    parsed = parse_resume_text(candidate.get(\"resume_text\", \"\"))\n    candidate_summary = f\"Name: {candidate.get('name')}. Skills: {', '.join(parsed.get('skills', []))}.\"\n    prompt = f\"\"\"\nYou are an HR offboarding assistant for role: {role_title}.\nCandidate info: {candidate_summary}\n\nProduce:\n1) Exit checklist with tasks (revoke accesses, asset return, etc).\n2) Knowledge transfer notes summary.\n3) Suggested timeline (days).\n\nReturn JSON: {{ \"checklist\": [...], \"knowledge_transfer\": \"...\", \"timeline_days\": N }}\n\"\"\"\n    return prompt\n\ndef generate_offboarding(candidate, role_title):\n    prompt = build_offboarding_prompt(candidate, role_title)\n    return call_agent_and_parse(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.677393Z","iopub.status.idle":"2025-12-01T19:20:54.677711Z","shell.execute_reply.started":"2025-12-01T19:20:54.677537Z","shell.execute_reply":"2025-12-01T19:20:54.677551Z"}},"outputs":[],"execution_count":null},{"id":"1a8a8d77","cell_type":"markdown","source":"## Performance review (prompt + function)\nSummarize feedback and propose goals.","metadata":{}},{"id":"ad62320b","cell_type":"code","source":"def build_performance_prompt(name, feedback_list):\n    prompt = f\"\"\"\nYou are an HR performance review assistant.\nEmployee: {name}\nFeedback: {feedback_list}\n\nProduce:\n1) Concise performance summary (3-4 sentences).\n2) Strengths (3 bullets).\n3) Areas for improvement (3 bullets).\n4) Suggested goals for next period.\n\nReturn JSON: {{ \"summary\": \"...\", \"strengths\": [...], \"improvements\": [...], \"goals\": [...] }}\n\"\"\"\n    return prompt\n\ndef generate_performance(name, feedback_list):\n    prompt = build_performance_prompt(name, feedback_list)\n    return call_agent_and_parse(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.680033Z","iopub.status.idle":"2025-12-01T19:20:54.680495Z","shell.execute_reply.started":"2025-12-01T19:20:54.680222Z","shell.execute_reply":"2025-12-01T19:20:54.680239Z"}},"outputs":[],"execution_count":null},{"id":"94ee7941","cell_type":"markdown","source":"## Scheduler & Email (mock)\nMock calendar slot finder and email sending. Replace with real API when needed.","metadata":{}},{"id":"2bf5db76","cell_type":"code","source":"def mock_calendar_find_slots(preferred_days=3, slots_per_day=3):\n    now = datetime.datetime.now()\n    slots = []\n    for d in range(1, preferred_days+1):\n        day = now + datetime.timedelta(days=d)\n        for s in range(slots_per_day):\n            slot_time = (day.replace(hour=10 + s*2, minute=0, second=0, microsecond=0)).isoformat()\n            slots.append(slot_time)\n    return slots\n\ndef send_mock_email(to, subject, body):\n    log(f\"[MOCK EMAIL] To: {to} | Subject: {subject}\\n{body[:200]}...\")\n    return {\"status\": \"sent\", \"to\": to, \"subject\": subject}\n\ndef propose_slots_for_candidate(candidate_email):\n    slots = mock_calendar_find_slots()\n    return {\"candidate\": candidate_email, \"proposed_slots\": slots[:5], \"status\": \"proposed\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.681752Z","iopub.status.idle":"2025-12-01T19:20:54.682123Z","shell.execute_reply.started":"2025-12-01T19:20:54.681921Z","shell.execute_reply":"2025-12-01T19:20:54.681937Z"}},"outputs":[],"execution_count":null},{"id":"2ee31a68","cell_type":"markdown","source":"## MCP (Multi-Component Processor) registry\nRegister components (screen/onboard/offboard/schedule/metrics) for orchestration through names.","metadata":{}},{"id":"6797fc73","cell_type":"code","source":"MCP = {}\n\ndef register_component(name, fn):\n    MCP[name] = fn\n    log(f\"Registered MCP component: {name}\")\n\ndef call_component(name, *args, **kwargs):\n    if name not in MCP:\n        raise ValueError(f\"Component {name} not registered\")\n    return MCP[name](*args, **kwargs)\n\n# register components (functions)\nregister_component(\"screen\", lambda df, jd=JOB_JD: batch_screen_candidates(df, jd))\nregister_component(\"parallel_screen\", lambda df, jd=JOB_JD: parallel_batch_screen_candidates(df, jd))\nregister_component(\"onboard\", lambda candidate, role: generate_onboarding(candidate, role))\nregister_component(\"offboard\", lambda candidate, role: generate_offboarding(candidate, role))\nregister_component(\"schedule\", lambda email: propose_slots_for_candidate(email))\nregister_component(\"performance\", lambda name, feedback: generate_performance(name, feedback))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.683395Z","iopub.status.idle":"2025-12-01T19:20:54.683720Z","shell.execute_reply.started":"2025-12-01T19:20:54.683545Z","shell.execute_reply":"2025-12-01T19:20:54.683562Z"}},"outputs":[],"execution_count":null},{"id":"822b4025","cell_type":"markdown","source":"## Memory (in-memory + file-backed)\nImplement small in-memory dict and file-backed persistent store for contexts.","metadata":{}},{"id":"8436f1ba","cell_type":"code","source":"# in-memory\nmemory_store = defaultdict(list)\n\ndef memory_add(key, message):\n    memory_store[str(key)].append({\"ts\": datetime.datetime.now().isoformat(), \"text\": message})\n\ndef memory_get_context(key, max_tokens=1500):\n    msgs = [m[\"text\"] for m in memory_store.get(str(key), [])]\n    return compact_context(msgs, max_tokens=max_tokens)\n\n# file-backed persistent memory\npersistent_memory = safe_read_json(MEMORY_FILE) or {}\n\ndef persistent_memory_add(key, message):\n    persistent_memory.setdefault(str(key), []).append({\"ts\": datetime.datetime.now().isoformat(), \"text\": message})\n    safe_write_json(MEMORY_FILE, persistent_memory)\n\ndef persistent_memory_get_context(key, max_tokens=1500):\n    msgs = [m[\"text\"] for m in persistent_memory.get(str(key), [])]\n    return compact_context(msgs, max_tokens=max_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.684851Z","iopub.status.idle":"2025-12-01T19:20:54.685543Z","shell.execute_reply.started":"2025-12-01T19:20:54.685338Z","shell.execute_reply":"2025-12-01T19:20:54.685357Z"}},"outputs":[],"execution_count":null},{"id":"506ce297","cell_type":"markdown","source":"## Evaluation & Metrics\nCompute simple metrics (strong % and avg coverage), save metrics to file and plot.","metadata":{}},{"id":"8424db18","cell_type":"code","source":"def evaluate_results(results, jd=JOB_JD):\n    total = len(results)\n    strong = sum(1 for r in results if (r.get(\"result\", {}).get(\"score\") or 0) >= 70)\n    coverages = []\n    for r in results:\n        matched = r.get(\"result\", {}).get(\"matched_skills\", []) or []\n        cov = 0\n        if jd.get(\"must_have\"):\n            cov = len(set(matched) & set(jd[\"must_have\"])) / max(1, len(jd[\"must_have\"]))\n        coverages.append(cov)\n    avg_cov = sum(coverages) / max(1, len(coverages))\n    metrics = {\"total\": total, \"strong_count\": strong, \"strong_pct\": (strong/total)*100 if total else 0, \"avg_must_have_coverage\": avg_cov}\n    fname = METRICS_DIR / f\"metrics_{int(time.time())}.json\"\n    safe_write_json(fname, metrics)\n    return metrics\n\ndef plot_metrics(metrics):\n    labels = [\"strong_pct\", \"avg_must_have_coverage\"]\n    values = [metrics[\"strong_pct\"], metrics[\"avg_must_have_coverage\"]]\n    plt.figure(figsize=(6,3))\n    plt.bar(labels, values)\n    plt.title(\"Screening Metrics\")\n    plt.ylabel(\"Value\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.686350Z","iopub.status.idle":"2025-12-01T19:20:54.686707Z","shell.execute_reply.started":"2025-12-01T19:20:54.686526Z","shell.execute_reply":"2025-12-01T19:20:54.686543Z"}},"outputs":[],"execution_count":null},{"id":"0e868b31","cell_type":"markdown","source":"## A2A exposure\nWrap service handler and expose via `to_a2a()` as in your main.ipynb. Use uvicorn scaffold optionally.","metadata":{}},{"id":"24adc254","cell_type":"code","source":"def hr_service_handler(payload):\n    try:\n        action = payload.get(\"action\")\n        if action == \"screen\":\n            candidates = payload.get(\"candidates\")\n            df = pd.DataFrame(candidates) if candidates else df_people\n            return {\"status\": \"ok\", \"results\": batch_screen_candidates(df, JOB_JD)}\n        elif action == \"parallel_screen\":\n            candidates = payload.get(\"candidates\")\n            df = pd.DataFrame(candidates) if candidates else df_people\n            return {\"status\": \"ok\", \"results\": parallel_batch_screen_candidates(df, JOB_JD)}\n        elif action == \"onboard\":\n            candidate = payload.get(\"candidate\")\n            role = payload.get(\"role\", \"Employee\")\n            return {\"status\": \"ok\", \"result\": generate_onboarding(candidate, role)}\n        elif action == \"offboard\":\n            candidate = payload.get(\"candidate\")\n            role = payload.get(\"role\", \"Employee\")\n            return {\"status\": \"ok\", \"result\": generate_offboarding(candidate, role)}\n        elif action == \"schedule\":\n            email = payload.get(\"email\")\n            return {\"status\": \"ok\", \"proposal\": propose_slots_for_candidate(email)}\n        elif action == \"performance\":\n            name = payload.get(\"name\")\n            feedback = payload.get(\"feedback\", [])\n            return {\"status\": \"ok\", \"result\": generate_performance(name, feedback)}\n        else:\n            return {\"status\": \"error\", \"message\": f\"unknown action {action}\"}\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": str(e)}\n\nhr_agent_a2a = to_a2a(hr_service_handler)\nlog(\"Prepared HR service as A2A agent (hr_agent_a2a).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.687848Z","iopub.status.idle":"2025-12-01T19:20:54.688115Z","shell.execute_reply.started":"2025-12-01T19:20:54.687968Z","shell.execute_reply":"2025-12-01T19:20:54.687978Z"}},"outputs":[],"execution_count":null},{"id":"e1f9f642","cell_type":"markdown","source":"### Optional: Run A2A via uvicorn locally\nOnly use in a local environment that supports uvicorn. Keep commented on Kaggle.","metadata":{}},{"id":"01ddfc40","cell_type":"code","source":"# import uvicorn\n# from fastapi import FastAPI\n#\n# app = FastAPI()\n#\n# @app.post(\"/a2a/hr\")\n# def hr_endpoint(payload: dict):\n#     return hr_service_handler(payload)\n#\n# if __name__ == \"__main__\":\n#     uvicorn.run(app, host=A2A_HOST, port=A2A_PORT)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.689262Z","iopub.status.idle":"2025-12-01T19:20:54.689536Z","shell.execute_reply.started":"2025-12-01T19:20:54.689395Z","shell.execute_reply":"2025-12-01T19:20:54.689407Z"}},"outputs":[],"execution_count":null},{"id":"0f95d941","cell_type":"markdown","source":"## Smoke tests / examples\nExample calls (comment out to avoid LLM calls while developing). Use these to validate flows.","metadata":{}},{"id":"0591d45d","cell_type":"code","source":"# Example 1: Sequential screening (will call your LLM)\n# results_seq = batch_screen_candidates(df_people, JOB_JD)\n# print(results_seq)\n\n# Example 2: Parallel screening\n# results_par = parallel_batch_screen_candidates(df_people, JOB_JD)\n# print(results_par)\n\n# Example 3: Iterative refinement\n# refined = iterative_refinement(people, JOB_JD, max_iters=3)\n# print(refined)\n\n# Example 4: Onboarding\n# print(generate_onboarding(people[0], JOB_JD[\"title\"]))\n\n# Example 5: Offboarding\n# print(generate_offboarding(people[1], JOB_JD[\"title\"]))\n\n# Example 6: Performance\n# print(generate_performance(people[0][\"name\"], [\"Delivered X\", \"Needs better docs\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:20:54.690661Z","iopub.status.idle":"2025-12-01T19:20:54.690952Z","shell.execute_reply.started":"2025-12-01T19:20:54.690802Z","shell.execute_reply":"2025-12-01T19:20:54.690817Z"}},"outputs":[],"execution_count":null},{"id":"9c79c537","cell_type":"markdown","source":"## Next steps / Important note\n- If your `main.ipynb` uses a different exact LlmAgent method name (e.g., `.invoke()` / `.predict()`), replace the single line `resp = hr_agent.run(prompt)` inside `call_agent_and_parse()` with your exact call.\n- Replace mock tools with real integrations (search/calendar/email) if you want production connectivity â€” add required Kaggle secrets.\n- If you want I can now: (A) Replace `hr_agent.run()` calls with the verbatim lines from your `main.ipynb`, (B) Produce a .ipynb file for download, or (C) Add unit tests and labeled evaluation data.","metadata":{}},{"id":"ad714113-eb74-4bcd-8de4-4e1a05da89bb","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}